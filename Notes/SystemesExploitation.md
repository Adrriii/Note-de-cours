# Systèmes d'exploitation

[TOC]

Un système : ça marche comment, pourquoi ça marche comme ça ?

## Introdution aux systèmes d'exploitation

Système d'exploitation = machine virtuelle abstraite.

L'OS fournit les services suivants :

* Factorisation de code (protocole de périphériques)
* Services de *haut niveau* (fichiers, GUI, ...)
* Arbitrage d'accès au matériel (CPU, mémoire, ...)

#### Démarrage d'un pc

* Le CPU se réveille. Il execute des instructions depuis le BIOS (Basic Input/Output System). Il découvre et vérifie le matériel.

* Le CPU doit charger le système. Le BIOS possède l'information *quel volume utiliser*.

  ​				

  ​													*(shéma démarrage*)

  

Mode utilisateur : Seul un sous-ensemble du jeu d'instruction est accessible.

Le processeur à deux modes de fonctionnement :

* Mode utilisateur (*protégé*)
* Mode noyeau (*réel*)

Impossible de passer du mode utilisateur en mode noyeau, instruction non disponible dans le sous-ensemble en mode utilisateur.

Lors d'un printf, un appel système est réalisé avec par exemple `syscall`. Les paramètre peuvent être fourni au noyeau en les mettants dans un registre (linux: `%eax`). Le noyeau possède une table des vecteurs d'interuption.

|                       |
| :-------------------: |
| Processus utilisateur |
|    Appels systèmes    |
|        Noyeau         |
|       Matériel        |



Nachos est une simulation de système. C'est à dire que nachos est un processus utilisateur, qui simule des appels systèmes. Pour ne pas se faire intérompre par le noyeau linux, il utilise un interpréteur MIPS. 

## Gestion de processus



*Processus :* Instance d'un programme en cours d'exécution.

Le noyeau doit allouer au minimum :

* Espace d'adressage = liste d'emplacements mémoire <br>

  | code | data | tas $\rightarrow$ | lib dynamique |      | $\leftarrow$  pile |
  | ---- | ---- | ----------------- | :-----------: | ---- | ------------------ |

* Structure dans le noyeau contenant des informations utiles :
  * cartographie de la mémoire du processus
  * espace de sauvegarde des registres (seulement certains systèmes)
  * identifiant de l'utilisateur
  * Pid
  * État
  * Priorité



<img src="images/illustrationSE.png" style="zoom:100%;" />

Lorsque aucune tâche n'est prête, ou en train de tourner, un processus par défaut est  exécuté par le processeur. C'est le processus `idle`, qui a une priorité de -10 000.

### Ordonnancement de processus 



> Comment ordonnancer des processus dans un système interactif ?

Plusieurs stratégies sont possibles.

Stratégie FIFO: les processus sont placés dans une file. Si le processus en tête rend la main, on change. (utilisé par nachos). Simple, mais risque de *famine* (pas de temps processeur si un processus prends tout).

Stratégie Round-Robin (tourniquet): Tous les processus ont le même temps d'exécution, changement à intervalles régulier. Problème: si 100 processus et 10ms chacun,  il faut 1 seconde pour revenir au processus courant.

Stratégie par priorité: on exécute toujours la tache de priorité la plus élevée.

Stratégie par *lots* (batch): On doit dans un premier temps estimer la durée d'un processus. On doit ensuite minimiser le temps d'attente (de restitution) moyen.

**Exemple**  Quatre travaux, a, b ,c, d, soumis en même temps.

Temps de restitution : $\left. \begin{array}{ll} a: a\\b : a + b\\c:a + b + c\\d:a+b+c+d \end{array} \right\} \frac{4a+3b+2c+d}{4}$  On met le plus long en dernier pour réduire l'attente moyenne.

Dans le cas d'un système interactif, on ne connaît pas la durée du prochain quantum de temps que prendra un processus sur le processeur. Malheureusement, on ne connaît pas l'avenir, mais on peut le prédire/estimer.

$Estimation_{n+1} = \alpha Estimation_n+(1-\alpha)durée_n\\Estimation_0 \rightarrow Pire\ des\ cas.$ 	$\alpha = 0 \rightarrow trop\ réactif\\ \alpha = 1 \rightarrow ne\ change\ jamais\\ \alpha=\frac{1}{2} \rightarrow S'adapte\ bien.$ 

La priorité sera l'inverse de l'estimation.

#### Linux 2.4

La priorité donne droit à un certain nombre de *crédits*.

Soient trois processus $P_1:4\\P_2:2\\P_3:2$ 	

On a alors :

$$ P_1(reste:3) \rightarrow P_1(2) \rightarrow \underbrace{P_1(1)}_{On\ prends\ P_1\ \\car\ déjà\ présent\\sur\ le\ processeur.} \rightarrow P_2(1) \rightarrow P_3(1) \rightarrow P_3(0) \rightarrow P_2(0) \rightarrow P_1(0)$$

À la fin, quand il n'y a plus de jetons, c'est la fin d'une *époque*. Il faut redistribuer les jetons.

### Thread vs Processus

**Processus :** Flôt d'exécution + espace d'addressage (`fork` : Copie de l'espace du père, espace disjoint)

**Thread :** Flôt d'exécution

```c
int i = 0;

void *f(void *arg) {
    i = 5;
    printf("I am %p\n", pthread_self());

    return NULL;
}

int main() {
    pthread_t t;
    pthread_create(&t, NULL, f, NULL);

    pthread_join(t, NULL)
    // Ici, i vaut 5
}
```

Prenons par exemple ce code :
```c
int n = 0;

void *f(void *arg) {
    for (int i = 0; i < 100; i++) {
        n++
    }

    return NULL;
}

int main() {
    pthread_t thread_1, thread_2;
    pthread_create(&thread_1, NULL, f, NULL);
    pthread_create(&thread_2, NULL, f, NULL);

    pthread_join(thread_1, NULL);
    pthread_join(thread_2, NULL);

    printf("%d\n", n);
}
```

A la fin, `n` peut ne pas valoir 200. `n` peut en effet prendre des valeurs dans l'interval [2, 200]. Cela peut arriver car en réalité `n++` n'est pas une instruction unique, mais une suite d'instruction qui peut ressembler à quelque chose comme ça :
```asm
load r1 @n
incr r1
write @n r1
```

Et ces instructions des deux threads peuvent *s'entreméler*.

#### Synchronisation
* Au plus un thread peut exécuter un code *sensible*
* Attendre qu'un évènement se produise avant de continuer.

Le premier point s'appel **exclusion mutuelle**
```c
entrer_sc();
{
    //Code sensible = Section critique
}
sortie_sc()
```

On pourrait imaginer un système de verrou pour protéger une section critique comme dans le premier point. On aurait alors :
```c
int verrou = 0; //0 liber/1 occupé

void entrer_sc() {
    while(verrou == 1) ;
    verrou = 1.
}

void sortie_sc() {
    verrou = 0;
}
```

Mais en réalité, ce code ne marche pas ! En effet, deux thread peuvent faire un `load` du verrou en même temps, et entrer en section critique.

Voici une version un peu plus avancé utilisant un système de *flag* :

```c
//Ici, il y a deux processus, P1 et P2
int tour = 0;
bool drapeau[2] = {false, false};

void entrer_sc() {
    drapeau[i] = true;
    tour = i;

    attendre(drapeau[1 - i] == false || tour = 1 - i);
}

void sortie_sc() {
    drapeau[i] = false;
}
```
Ce code fonctionne avec deux processus. Il y a des version pour n processus, avec n étapes à franchire. Mais avec cette technique nous sommes obligé de fixer à l'avance le nombre d'accès concurents pouvant être réalisé.


Pour résoudre ce problème, nous avons une solution *matérielle*. Il s'agit d'une instruction atomique `test_and_set`(tas). Si c'était une fonction `c`, voici à quoi elle ressemblerait :

```c
int test_and_set(int *p) {
    int old = *p
    *p = 1;

    return old;
}
```

On remarque que si plusieurs threads exécutent cette fonction, un seul aura comme valeur de retour 0 ! C'est grâce à l'atomicité de l'instruction. Elle ne peut pas être *coupé en deux*. On peut alors réécrire notre solution utilisant un verrou :

```c
int v = 0;

void entrer_sc() {
    while(teset_and_set(&v))
        while(v == 1)   // On attends que le verrour repace à 0, moins couteux
}

void sortie_sc() {
    v = 0;
}
```

Voila, ce code fonctionne. Mais il a un défaut majeur. L'attente est *active*. C'est-à-dire que 100% du processeur est utilisé ! Les conditions d'ordonnancement sont catastrophiques.

Une solution est alors de *Bloquer* les processus en attente.

### Les Sémaphores

```c
struct {
    int value;
    list_t processus_attente;
}
```

Deux opérations sont disponibles sur les sémaphores.
```c
P(s) {
    valeur--;
    si valeur < 0:
        se bloque dans la liste
} //Bloquant

V(s) {
    valeur++;
    si valeur >= 0:
        réveille un processus de la liste
} //Non-bloquant
```

**Mettre shéma rendez-vous !**

Sémaphore avec un seul jetton : Permet de protéger section critique.
On appel ce genre de sémaphore des *mutex*.

#### Thread voulant se synchroniser sur *barrière*

```c
void barrier() {
    P(mutex);

    if (nb < N) {
        V(mutex);   // Doit être après tout utilisation de nb
        P(wait);
    } else {
        nb = 0;
        V(mutex);

        for (int i = 0; i < N - 1; i++) {
            V(wait);
        }
    }
}
```

##### Producteur/consomateur

```c
Semaphore cons(0), prod(MAX), mutex(1);
//Il faut ajouter le mutex seulement dans le cas ou
// on ne peut écrire et lire en même temps.

void production(tube_t e) {
    P(prod);
    // P(mutex)
    put(e);
    // V(mutex)
    V(cons);
}

void consomation(tube_t e) {
    P(cons);
    // P(mutex)
    get(e);
    // V(mutex)
    V(prod);
}

```

-------------
Certaines structures de données ont des opérations de deux types :

* Celles qui modifient la structure.
* Celles qui la consultent.

Dans notre exemple avec un fichier texte, nous avons les rédacteurs (insertion, suppression) et les lecteurs (lecture). On peut lire à plusieurs sans rédacteur. Les rédacteurs peuvent être 1 à la fois.

```c
void lecteur() {
    P(Sas);
    P(mutex);

    if (++nb == 1) {
        P(write);
    }

    V(mutex);
    V(Sas);

    lire();

    P(mutex);
    if (--nb == 0) {
        V(write);
    }
    V(mutex);
}

void redacteur() {
    P(Sas);
    P(write);

    ecrire();

    V(write);
    V(Sas);
}
```

Problème : Code non équitable, lecteur ultra prioritaire. --> ajout du sas (mutex(1));

Simula (1962, Hoave) nouveau concept, le *moniteur*

```c
begin monitor(m)
    int n;
    procedur p1{ n++; }
    procedur p2{ n--; }
end monitor
```

exclusion mutuelle implicite entre les exécutions des procédures d'un moniteur. Pour mettre en oeuvre des synchronisations plus générales, on utilise des *conditions*.

```c
begin monitor(n)
int n;
condition c;

procedure p1 {
    if (...)
        wait(c);    // Bloquage inconditionnel
}

procedure p2 {
    if (...)
        signal(c);  // Réveil un processus bloqué sur la condition, ou ne fait rien.
}

```

On peut également utiliser `bcoast`, qui réveil tout ceux qui attendent.

En C :

```c
pthread_mutex_t_monitor monitor;
pthread_cond_t cond;

void p1() {
    pthread_mutex_lock(&monitor);

    if (...)
        pthread_cond_wait(&c, &m);

    pthread_mutex_unlock(&monitor);
}

void p2() {
    pthread_mutex_lock(&m);

    if (...)
        pthread_cond_signal(&c);

    pthread_mutex_unlock(&m);
}
```

Exemple d'utilisation : barrière

```c
barriere() {
    mutex_lock(&m);

    if (++nb < MAX)
        cond_wait(&wait, &m);
    else
        cond_bcast(&wait);

    mutex_unlock(&m);
}
```

Exemple producteur/consomateur

```c

mutex_t m;
cond_t prod, cons;
int nbe = 0;

void producteur() {
    mutex_lock(&m);
    if (nbe == MAX) {
        cond_wait(&prod, &m);
    }

    put(...);
    nbe++;
    cond_signal(&cons);
    mutex_unlock(&m);
}

void consomateur() {
    mutex_lock(&m);

    if (nbe == 0) {
        cond_wait(&cons, &m);
    }
    get(...);
    nbe--;
    cond_signal(&prod); // Pas grave si personne attends, grâce à nbe
    mutex_unlock(&m);
}

```

Problème lorsque l'on relache le mutex. Pour résoudre ce problème, il faut mettre des while devant les `cond_wait` systématiquement.

Pourquoi on utilise les mutex et pas les sémaphores ?

Robot pathFinder, envoyé sur mars (1995?). 

Tache haute prioritée périodique (si elle n'apparait pas, le système reboot).

Tache priorité moyenne, temps long.

Tache basse priorité, même mutex.

Tache low exécuté, mutex lock. Pendant quelle avait le mutex, high se réveille, essay de prendre le mutex. Elle se bloque et repasse la main à low, mais la tache med se réveille, et prends le mutex. Le robot se met à reboot.

Pour éviter, transmission de priorité. Le low devient high, et dès qu'il relache il redevient low. Pas possible avec les sémaphores.

# Gestion mémoire

Avec les bandes magnétiqus, les programmes ont commencé à pouvoir efféctuer des E/S.
Le but était alors d'optimiser le temps processeur en charchant plusieurs processus en mémoire, même s'ils ne sont qu'un à la fois à s'exécuter (pour utiliser le temps d'E/S).

1er problème : à la compilation, on ignore le futur emplacement en mémoire.
Le chargeur peut translater les références mémoires si le compilateur fournit un code + une table qui indique toute les positions des références mémoire.

2eme problème : Comment garantir qu'un processus ne puisse pas accéder à la mémoire des autres ? 
L'architecture des processeur à évoluée pour permettre la coéxistence simultanée de plusieurs processus en mémoire. On ajoute deux registres, un contenant la limite de la taille en mémoire du processus, et l'autre le début de cette mémoire.
